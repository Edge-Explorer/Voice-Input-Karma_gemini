{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "273c139c-0955-4bd1-bb40-b7c095f11db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dependencies\n",
    "\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import ast\n",
    "import pandas\n",
    "import sys\n",
    "import time\n",
    "import requests  \n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43368e78-5cf4-4f89-af2e-b37441adb690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize recognizer and text-to-speech engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 150)  # Adjust speech rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c464fea-0f6e-4752-b627-4f81533cd121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 166 records...\n",
      "Inserted 166 records...\n",
      "Inserted 166 records...\n",
      "Inserted 166 records...\n",
      "Inserted 166 records...\n",
      "Inserted 166 records...\n",
      "Inserted 166 records...\n",
      "Inserted 73 records...\n",
      "✅ All data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# data=pandas.read_csv('Content_Storage_df.csv')\n",
    "# embedding_df=pandas.DataFrame(data)\n",
    "# embedding_df.head(1)\n",
    "# chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "# collection = chroma_client.get_or_create_collection(\"karma_embeddings\")\n",
    "\n",
    "# BATCH_SIZE = 166  # ChromaDB's max batch size\n",
    "\n",
    "# def insert_data(df):\n",
    "#     # Ensure embeddings are in the correct format (list of floats)\n",
    "#     df[\"embedding_vector\"] = df[\"embedding_vector\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    \n",
    "#     # Convert verse_id to float format for uniqueness\n",
    "#     df[\"verse_id\"] = df.apply(lambda row: float(f\"{row['chapter_id']}.{row['verse_id']}\"), axis=1)\n",
    "\n",
    "#     # Insert data in batches\n",
    "#     for i in range(0, len(df), BATCH_SIZE):\n",
    "#         batch = df.iloc[i : i + BATCH_SIZE]\n",
    "\n",
    "#         collection.add(\n",
    "#             ids=batch[\"verse_id\"].astype(str).tolist(),      # Convert verse_id to string\n",
    "#             documents=batch[\"verse_text\"].tolist(),          # List of verses\n",
    "#             embeddings=batch[\"embedding_vector\"].tolist()    # List of embeddings\n",
    "#         )\n",
    "#         print(f\"Inserted {len(batch)} records...\")\n",
    "\n",
    "#     print(\"✅ All data inserted successfully!\")\n",
    "\n",
    "# # Call function to insert your data\n",
    "# insert_data(embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c62ba84a-c5ba-4282-9fb1-b7c4bffc01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = chroma_client.get_collection(\"karma_embeddings\")\n",
    "genai.configure(api_key=\"Google Gemini Key")\n",
    "history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c526592b-ca1a-49e2-a646-2accaf0c3b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8190,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "retrieve_grader_1 = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash-8b\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\"\"\"You are a grader assessing the relevance of a retrieved document to a user question. \n",
    "                        Give a binary score 'yes' or 'no' to indicate whether the document is relevant.\n",
    "                        Provide the binary score as JSON with a single key 'score'.\n",
    "                        input format is 'question : question , document : document'. \"\"\"\n",
    ")\n",
    "web_search_1_5= genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash-8b\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\"\"\"You are an AI assistant specialized in retrieving spiritual and positive context from the Garud Puran.  \n",
    "                        Use the given question to extract a meaningful and relevant context that aligns with the teachings of the Garud Puran.  \n",
    "                        \n",
    "                        If the user asks about their **karma, actions, or deeds**, retrieve context that explains both the **pros and cons** based on what will happen in **Swarg (heaven) and Nark (hell)** according to the Garud Puran and Sanatan Dharma.  \n",
    "                        Ensure the context clearly describes the **specific rewards in Swarg** for good deeds, bringing peace and happiness, and the **specific punishments in Nark** for bad deeds, leading to suffering and atonement.  \n",
    "                        The context should also highlight the **emotional and spiritual consequences** of one's actions, helping the user understand the **joy behind righteousness** and the **pain behind sinful acts**.  \n",
    "                        \n",
    "                        For **general queries**, retrieve an example from the Garud Puran that illustrates the concept in a way that makes it relatable and insightful.  \n",
    "                        \n",
    "                        Ensure the context is spiritually uplifting, guiding the user toward self-reflection and improvement, while keeping it concise (maximum of three paragraphs).  \n",
    "                        Each retrieved context should be **unique**, providing fresh insights or varying perspectives while staying true to the scripture's teachings.  \n",
    "                        Use **simple and clear English**, avoiding complex words, so the response is easy to understand for all users.  \n",
    "\n",
    "                        \"\"\"\n",
    ")\n",
    "answer_generator_2 = genai.GenerativeModel(\n",
    "  model_name=\"gemini-2.0-pro-exp-02-05\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction= \"\"\"You are an AI assistant designed for question-answering tasks based on the Garud Puran.\n",
    "                        \n",
    "                        Use the retrieved context to generate an accurate and spiritually meaningful response.  \n",
    "                        Ensure that the answer aligns with the teachings of the Garud Puran and maintains a positive and enlightening tone.  \n",
    "                        \n",
    "                        If the user asks about their **karma, actions, or deeds**, include both the **pros and cons** based on what will happen in **Swarg (heaven) and Nark (hell)** according to the Garud Puran and Sanatan Dharma.\n",
    "                        Clearly mention the **specific rewards in Swarg** for good deeds and the **specific punishments in Nark** for bad deeds, as described in the scriptures.  \n",
    "\n",
    "                        For **general queries**, provide a relevant example from the Garud Puran to illustrate the concept effectively.\n",
    "\n",
    "                        ### **Response Structure:**  \n",
    "                        1️⃣ **First, directly answer the question.**  \n",
    "                           - Describe the **specific punishments in Nark (hell)** or **specific rewards in Swarg (heaven)** based on their karma, as per the Garud Puran.  \n",
    "                           - Help the user understand the **joy and blessings** their good deeds bring and the **pain and suffering** caused by their bad deeds.  \n",
    "                        \n",
    "                        2️⃣ **Then, provide guidance on how to resolve or approach the problem from a spiritual perspective.**  \n",
    "                           - Explain how the user can **overcome negative karma** through righteous actions, devotion, and self-correction.  \n",
    "                           - Offer spiritual remedies or practices from the Garud Puran to seek divine grace and move toward a better path.  \n",
    "                        \n",
    "                        3️⃣ **Finally, include a general spiritual thought or insight related to the question.**  \n",
    "                           - Inspire the user with a **positive message about karma** and the cycle of cause and effect.  \n",
    "                           - Reinforce that **good deeds lead to inner peace and happiness**, while **wrong actions create suffering, but redemption is always possible through wisdom and self-improvement**.  \n",
    " \n",
    "                        \n",
    "                        Keep your response concise, with a maximum of three sentences.  \n",
    "                        End with a positive thought related to the question, inspired by the spiritual wisdom of the Garud Puran.  \n",
    "                        Use **simple and clear English**, avoiding complex words, so the response is easy to understand for all users.\n",
    "                        **Respond in the same language in which the user asks the question.**  \n",
    "                        \"\"\"\n",
    "  # system_instruction=\"\"\"You are an AI assistant designed for question-answering tasks based on the Garud Puran.  \n",
    "\n",
    "  #                       Use the retrieved context to generate an accurate and spiritually meaningful response.  \n",
    "  #                       Ensure that the answer aligns with the teachings of the Garud Puran and maintains a positive and enlightening tone.  \n",
    "                        \n",
    "  #                       ### **Handling Different Types of Questions:**  \n",
    "  #                       🟢 **For karma-related queries**  \n",
    "  #                       - Include both the **pros and cons** of their actions based on **Swarg (heaven) and Nark (hell)** as per the Garud Puran and Sanatan Dharma.  \n",
    "  #                       - Clearly describe **specific rewards in Swarg** for good deeds and **specific punishments in Nark** for bad deeds.  \n",
    "                        \n",
    "  #                       🟢 **For general queries about the Garud Puran**  \n",
    "  #                       - Provide an **explanation or summary of relevant teachings** from the scripture.  \n",
    "  #                       - If possible, include **a related story, parable, or example** from the Garud Puran to illustrate the concept effectively.  \n",
    "  #                       - Ensure that the response remains **uplifting, thought-provoking, and spiritually insightful**.  \n",
    "                        \n",
    "  #                       ### **Response Structure:**  \n",
    "  #                       1️⃣ **First, directly answer the question.**  \n",
    "  #                          - If the question is **karma-related**, explain the **Swarg/Nark consequences**.  \n",
    "  #                          - If the question is **general**, provide a **relevant explanation or story** from the Garud Puran.  \n",
    "\n",
    "  #                       2️⃣ **Then, offer guidance or wisdom related to the topic.**  \n",
    "  #                          - Provide insights into how the user can apply the knowledge in their life.  \n",
    "  #                          - If the question is about karma, suggest ways to **correct negative karma**.  \n",
    "  #                          - If it is a general query, explain **the deeper meaning or lesson** behind the concept.  \n",
    "                        \n",
    "  #                       3️⃣ **Finally, include a general spiritual thought or insight.**  \n",
    "  #                          - Inspire the user with a **positive message** from the Garud Puran.  \n",
    "  #                          - Reinforce **moral, ethical, and spiritual values** in a way that resonates with them.  \n",
    "                        \n",
    "                        # Keep your response concise, with a maximum of three sentences.  \n",
    "                        # End with a positive thought related to the question, inspired by the spiritual wisdom of the Garud Puran.  \n",
    "                        # Use **simple and clear English**, avoiding complex words, so the response is easy to understand for all users.  \n",
    "                        # **Respond in the same language in which the user asks the question.**  \n",
    "                        # \"\"\"\n",
    "  \n",
    ")\n",
    "hallucination_detection_3 = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash-8b\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\"\"\"You are verifying whether the model-generated answer is factually correct based on the provided context.  \n",
    "                        If the answer includes information not found in the context, classify it as hallucinated.  \n",
    "                        Respond with a JSON object containing a single key `\"hallucination\"`, with a value of `\"yes\"` or `\"no\"`.  \n",
    "                        \n",
    "                        Output Format:  \n",
    "                        {\n",
    "                          \"hallucination\": \"yes\"  // If the answer contains hallucinated information  \n",
    "                        }  \n",
    "                        {\n",
    "                          \"hallucination\": \"no\"   // If the answer is fully supported by the context  \n",
    "                        }   \"\"\"\n",
    ")\n",
    "question_resolving_detection_4 = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash-8b\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\"\"\"You are a grader evaluating whether an answer is useful in resolving the given question.  \n",
    "                        Assess if the answer is relevant, clear, and provides sufficient information to address the question.  \n",
    "                        Respond with a JSON object containing a single key `\"score\"`, with a value of `\"yes\"` or `\"no\"`.  \n",
    "                        \n",
    "                        Input Format:  \n",
    "                        question: {question}, answer: {answer}  \n",
    "                        \n",
    "                        Output Format:  \n",
    "                        {\n",
    "                          \"score\": \"yes\"  // If the answer is useful  \n",
    "                        }  \n",
    "                        {\n",
    "                          \"score\": \"no\"   // If the answer is not useful  \n",
    "                        }  \n",
    "                        \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d4f5428-4a7c-4fc2-9db8-0095be5d4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(question, top_k=3):\n",
    "    embedding_fn = embedding_functions.DefaultEmbeddingFunction()\n",
    "    question_embedding = embedding_fn([question])[0]\n",
    "\n",
    "    # Retrieve top-k matching documents\n",
    "    results = collection.query(\n",
    "        query_embeddings=[question_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    if results[\"documents\"]:\n",
    "        # print(results[\"documents\"])\n",
    "        flat_documents = [doc for sublist in results[\"documents\"] for doc in sublist]\n",
    "        return \" \".join(flat_documents) if flat_documents else \"No relevant context found.\"\n",
    "    \n",
    "    return \"No relevant context found.\"\n",
    "\n",
    "def retrieve_grader_function(question):\n",
    "    \n",
    "    chat_session = retrieve_grader_1.start_chat(\n",
    "                history=history\n",
    "            )\n",
    "    \n",
    "    response = chat_session.send_message(question)\n",
    "    \n",
    "    model_response=response.text\n",
    "    return model_response\n",
    "# Web search function \n",
    "def web_search(query, num_results=3):\n",
    "    \n",
    "    chat_session = web_search_1_5.start_chat(\n",
    "                history=history\n",
    "            )\n",
    "    \n",
    "    response = chat_session.send_message(query)\n",
    "    \n",
    "    model_response=response.text\n",
    "    return model_response\n",
    "    \n",
    "\n",
    "def answer_generator_function(question):\n",
    "    \n",
    "    chat_session = answer_generator_2.start_chat(\n",
    "                history=history\n",
    "            )\n",
    "    \n",
    "    response = chat_session.send_message(question)\n",
    "    \n",
    "    model_response=response.text\n",
    "    return model_response\n",
    "    \n",
    "def hallucination_detection_function(question):\n",
    "    \n",
    "    chat_session = hallucination_detection_3.start_chat(\n",
    "                history=history\n",
    "            )\n",
    "    \n",
    "    response = chat_session.send_message(question)\n",
    "    \n",
    "    model_response=response.text\n",
    "    return model_response\n",
    "\n",
    "def question_resolving_detection_function(question):\n",
    "    \n",
    "    chat_session = question_resolving_detection_4.start_chat(\n",
    "                history=history\n",
    "            )\n",
    "    \n",
    "    response = chat_session.send_message(question)\n",
    "    \n",
    "    model_response=response.text\n",
    "    return model_response\n",
    "#Full Path\n",
    "def Full_Flow(question):\n",
    "    flag=0\n",
    "    while True:\n",
    "        if flag==0:\n",
    "            document = retrieve_context(question)\n",
    "            model_input = f\"question : {question} , document : {document}\"\n",
    "            output = retrieve_grader_function(model_input)\n",
    "            \n",
    "            if 'yes' in output:\n",
    "                print('document found in database')\n",
    "            elif 'no' in output:\n",
    "                print('searching web.....')\n",
    "                print('document found on web.....')\n",
    "                document = web_search(question)\n",
    "        elif flag==1:\n",
    "            print('searching web.....')\n",
    "            print('document found on web.....')\n",
    "            document = web_search(question)\n",
    "        # print(document)\n",
    "        while True:   \n",
    "            #Generation of answer based on context\n",
    "            model_input = f\"question : {question},context : {document}\"\n",
    "            answer = answer_generator_function(model_input)\n",
    "            print('answer fetched from document')\n",
    "        \n",
    "            #Hallucination detection to check the correctness of answer\n",
    "            hallucination_check_input = f\"context : {document}, answer : {answer}\"\n",
    "            hallucination_output = hallucination_detection_function(hallucination_check_input)\n",
    "            if 'yes' in hallucination_output:\n",
    "                print('hallucination detected.')\n",
    "                print('regenerating the answer....\\n')\n",
    "                continue\n",
    "            elif 'no' in hallucination_output:\n",
    "                print('no hallucination detected')\n",
    "                question_resolver_input = f' question: {question}, answer: {answer}'\n",
    "                question_resolver_output = question_resolving_detection_function(question_resolver_input)\n",
    "                # print(question_resolver_output)\n",
    "                break\n",
    "            else: return None\n",
    "        if 'no' in question_resolver_output:\n",
    "            print('the generated answer do not resolve the query\\n')\n",
    "            print('searching the relevant document again.....\\n')\n",
    "            flag=1\n",
    "            continue\n",
    "            \n",
    "        elif 'yes' in question_resolver_output:\n",
    "            print('generated answer will resolve the query\\n\\n')\n",
    "            return 'answer :'+answer\n",
    "        else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f07c0e23-d740-41df-ab2b-c0a10b0507a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "document found in database\n",
      "answer fetched from document\n",
      "no hallucination detected\n",
      "generated answer will resolve the query\n",
      "\n",
      "\n",
      "answer :The Garuda Puran is a sacred Hindu text, a sister work to the Agni Puranam, that discusses both worldly knowledge and spiritual truths, essential for the followers of Brahmanism. It covers rituals, laws, medicine, and metaphysics, reflecting the knowledge of its time, and narrates how Lord Vishnu (Hari) described these teachings to Garuda, who then shared them with Kashyapa. Remember, the Garuda Puran guides us towards piety and fulfillment, showing that through devotion and right understanding, we can achieve a harmonious life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with sr.Microphone() as mic:\n",
    "            recognizer.adjust_for_ambient_noise(mic, duration=1)  # Better noise adjustment\n",
    "            print(\"Listening...\")\n",
    "\n",
    "            # Listen for user input with a timeout\n",
    "            audio = recognizer.listen(mic, timeout=5, phrase_time_limit=5)\n",
    "            question = recognizer.recognize_google(audio).lower()\n",
    "            \n",
    "            # question = \"What Arjuna Asked Krishna about war?\"\n",
    "            answer = Full_Flow(question)\n",
    "            print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666cf259-f5ed-456c-817e-a0a714246b57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
